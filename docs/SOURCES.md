# Sources

## Markov Chains

[Introducing Grammar Rules into Markov Chain](https://www2.hawaii.edu/~chin/661/Projects/AdvAI_Project_Report_Meek.pdf)

TODO: Study this notebook, it's very clear
[Markov Basics](https://github.com/unoti/markov-basics/blob/main/markov-basics.ipynb)

TODO: Study Norvig's work on ngrams
[ngrams](https://norvig.com/ngrams/)

TODO: Study this Shakespeare example
[Generative Character-Level Language Model](https://colab.research.google.com/github/norvig/pytudes/blob/main/ipynb/Goldberg.ipynb#scrollTo=WSuIHhK_DR9W)

TODO: Study the short code example
[17 Line Markov Chain](https://theorangeduck.com/page/17-line-markov-chain)

[Usenet 'bot' messages generated with Markov Chains (Mark V. Shaney)](https://en.wikipedia.org/wiki/Mark_V._Shaney)

## Parts of Speech Tagging

[Part of Speech Tagging (Stanford)](https://web.stanford.edu/~jurafsky/slp3/old_oct19/8.pdf)

[Natural Language Processing Lecture](https://hannibunny.github.io/nlpbook/03postagging/01tagsetsAndAlgorithms.html)

## Partially Observable Markov Decision Process Models

[Introduction to POMDPs](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13692)


# Alternative models for text generation

[Makemore (Andrej Karpathy)](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=4)